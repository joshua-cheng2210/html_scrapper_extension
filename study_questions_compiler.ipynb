{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "7bd6e8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import shutil\n",
    "import os\n",
    "import requests\n",
    "from pydoc import text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "7c117e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_process_directory = rf\"../Study questions to process\"\n",
    "processed_directory = rf\"../Study Questions processed\"\n",
    "\n",
    "default_raw_db_path = \"../public/study_quiz_raw_questions_db.json\"\n",
    "default_processed_by_quiz_db_path = \"../public/study_quiz_processed_questions_by_quiz_db.json\"\n",
    "default_processed_by_topics_db_path = \"../public/study_quiz_processed_questions_by_topics_db.json\"\n",
    "\n",
    "canvas_images_development_fp = \"../public/canvas_images.json\"\n",
    "img_dir_from_data_compilation = \"../public/img\"\n",
    "os.makedirs(img_dir_from_data_compilation, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "a2e3495f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created empty ../public/study_quiz_raw_questions_db.json\n"
     ]
    }
   ],
   "source": [
    "def reset_database_and_reprocess():\n",
    "    \"\"\"\n",
    "    Resets the database by removing JSON files and moving all processed files\n",
    "    back to the to-process directory for reprocessing.\n",
    "    \"\"\"\n",
    "    # Delete database files if they exist\n",
    "    if os.path.exists(default_raw_db_path):\n",
    "        os.remove(default_raw_db_path)\n",
    "    \n",
    "    if os.path.exists(default_processed_by_quiz_db_path):\n",
    "        os.remove(default_processed_by_quiz_db_path)\n",
    "    \n",
    "    # Create empty database files\n",
    "    with open(default_raw_db_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump({\"quizzes\": []}, f)\n",
    "        print(f\"Created empty {default_raw_db_path}\")\n",
    "    \n",
    "    # with open(default_processed_by_quiz_db_path, 'w', encoding='utf-8') as f:\n",
    "    #     json.dump([], f)\n",
    "    #     print(f\"Created empty {default_processed_by_quiz_db_path}\")\n",
    "    \n",
    "    # Ensure to_process_directory exists\n",
    "    os.makedirs(to_process_directory, exist_ok=True)\n",
    "    \n",
    "    # Move files back from processed to to-process\n",
    "    if os.path.exists(processed_directory):\n",
    "        moved_count = 0\n",
    "        for file in os.listdir(processed_directory):\n",
    "            if file.endswith(\".html\"):\n",
    "                source = os.path.join(processed_directory, file)\n",
    "                target = os.path.join(to_process_directory, file)\n",
    "                shutil.move(source, target)\n",
    "                moved_count += 1\n",
    "    else:\n",
    "        print(f\"Processed directory {processed_directory} does not exist\")\n",
    "\n",
    "# Usage example:\n",
    "reset_database_and_reprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "d0a53b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(default_raw_db_path):\n",
    "        with open(default_raw_db_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump({\"quizzes\": []}, f)\n",
    "\n",
    "\n",
    "if not os.path.exists(default_processed_by_quiz_db_path):\n",
    "        with open(default_processed_by_quiz_db_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump({\"quizzes\": []}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "edf8067b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning the texts\n",
    "def remove_invisible_chars(text):\n",
    "    invisible_chars = {\n",
    "        '\\u200b': 'Zero-width space',\n",
    "        '\\u00a0': 'Non-breaking space',\n",
    "        '\\u200c': 'Zero-width non-joiner',\n",
    "        '\\u200d': 'Zero-width joiner',\n",
    "        '\\ufeff': 'BOM',\n",
    "        '\\u2028': 'Line separator',\n",
    "        '\\u2029': 'Paragraph separator',\n",
    "        '\\u00ad': 'Soft hyphen'\n",
    "    }\n",
    "    for char in invisible_chars:\n",
    "        text = text.replace(char, '')\n",
    "    return text\n",
    "def remove_spaces(text):\n",
    "    \"\"\"Remove extra spaces and newlines from text.\"\"\"\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    text = re.sub(r'\\n\\s+', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = re.sub(r'\\n+', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text.strip()\n",
    "\n",
    "def completely_cleaned_text(text):\n",
    "    \"\"\"Clean up text by removing HTML tags, extra newlines, and normalizing whitespace.\"\"\"\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    text = remove_invisible_chars(text)\n",
    "    text = remove_spaces(text)\n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<[^>]+>', '', text)\n",
    "    text = text.replace('&lt;', '<')\n",
    "    text = text.replace('&gt;', '>')\n",
    "    text = text.replace('&nbsp;', ' ')\n",
    "    text = text.replace('&amp;', ' ')\n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "def clean_question(text):\n",
    "    \"\"\"Clean up text by removing HTML tags, extra newlines, and normalizing whitespace.\"\"\"\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    text = remove_invisible_chars(text)\n",
    "    \n",
    "    # Replace HTML entities\n",
    "    # text = text.replace('<sup>;', '^')\n",
    "    # text = text.replace('<br>;', ' ')\n",
    "    text = text.replace('&nbsp;', ' ')\n",
    "    text = text.replace('&amp;', ' ')\n",
    "    # Remove HTML tags\n",
    "    # text = re.sub(r'<[^>]+>', '', text)\n",
    "\n",
    "    text = text.replace('&lt;', '<')\n",
    "    text = text.replace('&gt;', '>')\n",
    "    \n",
    "    # # Replace newlines followed by spaces\n",
    "    text = re.sub(r'\\n\\s+', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = re.sub(r'\\n+', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    return text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425d3e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# html scrapping processes\n",
    "\n",
    "\n",
    "def get_canvas_img(url):\n",
    "    img_verifier = url.split(\"verifier=\")[-1].strip()\n",
    "    print(img_verifier)\n",
    "\n",
    "canvas_images = []\n",
    "\n",
    "def save_canvas_images_development():\n",
    "    with open(canvas_images_development_fp, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(canvas_images, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "def extract_quiz_to_json(html_path):\n",
    "    # Ensure we refer to the module-level canvas_images list when modifying it\n",
    "    global canvas_images\n",
    "    with open(html_path, encoding=\"utf-8\") as f:\n",
    "        soup = BeautifulSoup(f, \"html.parser\")\n",
    "\n",
    "    base_url=rf\"https://canvas.umn.edu\"\n",
    "\n",
    "    # Get quiz title from <title> tag\n",
    "    title_tag = soup.find(\"title\")\n",
    "    quiz_title = completely_cleaned_text(title_tag.text) if title_tag else \"\"\n",
    "    quiz_title = quiz_title.replace(\"Joshua Cheng's Quiz History: \", \"\").strip()\n",
    "    quiz_title = quiz_title.replace(\": BIOL 1009 (070-082) General Biology (Fall 2025)\", \"\").strip()\n",
    "    quiz_title = quiz_title.replace(\" (course resources and policies)\", \"\").strip()\n",
    "    \n",
    "    pattern = r'\\s*\\(due\\s+\\w+,\\s+\\w+\\.\\s+\\d+\\s+at\\s+[\\d:]+\\s+[AP]M\\)'\n",
    "    \n",
    "    # Replace the pattern with empty string\n",
    "    quiz_title = re.sub(pattern, '', quiz_title)\n",
    "\n",
    "    questions = []\n",
    "\n",
    "    def extract_image_url(html_string):\n",
    "        # Match image URLs in src attributes\n",
    "        html_string = str(html_string).strip()\n",
    "        if \"img\" not in html_string:\n",
    "            return []\n",
    "        \n",
    "        # Try with regular quotes first (which is what your examples have)\n",
    "        img_pattern = r'<img[^>]*src=\"([^\"]+)\"'\n",
    "        \n",
    "        # Find all matches\n",
    "        matches = re.findall(img_pattern, html_string)\n",
    "        \n",
    "        # If no matches, try with escaped quotes\n",
    "        if not matches:\n",
    "            img_pattern = r'<img[^>]*src=\\\\\"([^\"\\\\]+)\\\\\"'\n",
    "            matches = re.findall(img_pattern, html_string)\n",
    "\n",
    "        if matches:\n",
    "            # Build absolute URLs for any relative paths\n",
    "            img_urls = []\n",
    "            for match in matches:\n",
    "                if match.startswith('/'):\n",
    "                    img_urls.append(base_url + match)\n",
    "                else:\n",
    "                    img_urls.append(match)\n",
    "            \n",
    "            # print(html_string)\n",
    "            # print(img_urls)\n",
    "            # print(\"-\"*50)\n",
    "            return img_urls\n",
    "        else:\n",
    "            return []\n",
    "    \n",
    "    for q_holder in soup.find_all(\"div\", class_=\"question_holder\"):\n",
    "        question = {}\n",
    "        question_image_url = []\n",
    "\n",
    "        # Try to get question text - first from original_question_text, then from question_text\n",
    "        q_text = q_holder.find(\"div\", class_=\"original_question_text\")\n",
    "        if q_text and q_text.text.strip():\n",
    "            question_image_url = extract_image_url(q_text.text)\n",
    "            question_text = completely_cleaned_text(q_text.text)\n",
    "        else:\n",
    "            # Try getting question from question_text which may contain images\n",
    "            q_content = q_holder.find(\"div\", class_=\"question_text user_content enhanced\")\n",
    "            if q_content:\n",
    "                print(\"question_text user_content enhanced\")\n",
    "                question_image_url = extract_image_url(q_content.text)\n",
    "                # For questions with images, keep the HTML content\n",
    "                question_text = str(completely_cleaned_text(q_content))\n",
    "            else:\n",
    "                # Fall back to display_question\n",
    "                q_display = q_holder.find(\"div\", class_=\"display_question\")\n",
    "                if q_display:\n",
    "                    print(\"display_question\")\n",
    "                    # Sometimes question text is in aria-label or inside the div\n",
    "                    question_image_url = extract_image_url(q_display.text)\n",
    "                    question_text = completely_cleaned_text(q_display.get(\"aria-label\", \"\"))\n",
    "                    if not question_text:\n",
    "                        question_text = completely_cleaned_text(q_display.text)\n",
    "                else:\n",
    "                    question_text = \"\"\n",
    "\n",
    "        question[\"raw_html_question\"] = rf\"{remove_invisible_chars(q_text.text.strip())}\"\n",
    "        question[\"question\"] = question_text\n",
    "        question[\"question_image_url\"] = question_image_url\n",
    "        if question[\"question_image_url\"] and question[\"question_image_url\"] not in canvas_images:\n",
    "            # canvas_images is a plain list of urls; extend it with the new urls\n",
    "            canvas_images += question[\"question_image_url\"]\n",
    "            canvas_images = list(set(canvas_images)) \n",
    "            # print(f\"question['question_image_url']: {question['question_image_url']} : {get_canvas_img(question['question_image_url'])}\")\n",
    "\n",
    "        answers = []\n",
    "        correct_answer = None\n",
    "        for ans_div in q_holder.find_all(\"div\", class_=\"answer\"):\n",
    "            ans = {}\n",
    "            ans_text_div = ans_div.find(\"div\", class_=\"answer_text\")\n",
    "            ans_text = completely_cleaned_text(ans_text_div.text) if ans_text_div else \"\"\n",
    "            ans[\"text\"] = ans_text\n",
    "\n",
    "            # Detect correct answer by class or presence of correct arrow\n",
    "            is_correct = (\n",
    "                \"correct_answer\" in ans_div.get(\"class\", []) or\n",
    "                \"correct\" in ans_div.get(\"class\", []) or\n",
    "                ans_div.find(\"span\", class_=\"answer_arrow correct\")\n",
    "            )\n",
    "            ans[\"is_correct\"] = bool(is_correct)\n",
    "            if ans[\"is_correct\"]:\n",
    "                correct_answer = ans_text\n",
    "\n",
    "            # Get comment if present\n",
    "            # comment_div = ans_div.find(\"div\", class_=\"quiz_comment\")\n",
    "            # if comment_div:\n",
    "            #     comment_text = completely_cleaned_text(comment_div.text)\n",
    "            #     ans[\"comment\"] = comment_text\n",
    "            # else:\n",
    "            #     ans[\"comment\"] = None\n",
    "\n",
    "            answers.append(ans)\n",
    "\n",
    "        question[\"answers\"] = answers\n",
    "        question[\"correct_answer\"] = correct_answer\n",
    "\n",
    "        # Get any general comments for the question (outside answer divs)\n",
    "        quiz_comment_divs = q_holder.find_all(\"div\", class_=\"quiz_comment\")\n",
    "        # print(quiz_comment_divs)\n",
    "        \n",
    "        # Initialize comment fields\n",
    "        # question[\"correct_comments\"] = None\n",
    "        question[\"comments\"] = None\n",
    "        \n",
    "        if quiz_comment_divs:\n",
    "            \n",
    "            for comment_div in quiz_comment_divs:\n",
    "                neutral_p = comment_div.find(\"p\", class_=\"neutral_comments\")\n",
    "                if comment_div.text.strip() and neutral_p:\n",
    "                    # print(comment_div, \"\\n\", \"-\"*50)\n",
    "                    # all_comment_text.append(comment_div.text)\n",
    "                    if neutral_p:\n",
    "                        question[\"raw_html_comments\"] = remove_spaces(str(neutral_p))\n",
    "                        question[\"comments\"] = completely_cleaned_text(neutral_p.text)\n",
    "                        if question[\"raw_html_comments\"]:\n",
    "                            comments_img_url = extract_image_url(question[\"raw_html_comments\"])\n",
    "                            if comments_img_url:\n",
    "                                question[\"comments_image_url\"] = comments_img_url\n",
    "                                canvas_images += comments_img_url\n",
    "                                canvas_images = list(set(canvas_images))\n",
    "                            else:\n",
    "                                question[\"comments_image_url\"] = []\n",
    "\n",
    "                else:\n",
    "                    question[\"raw_html_comments\"] = None\n",
    "                    question[\"comments\"] = None\n",
    "                \n",
    "                # neutral_comments_p = comment_div.find(\"p\", class_=\"neutral_comments\")\n",
    "                \n",
    "                # if neutral_comments_p and not question[\"neutral_comments\"]:\n",
    "                #     question[\"neutral_comments\"] = completely_cleaned_text(neutral_comments_p.text)\n",
    "                #     # question[\"neutral_comments\"] = neutral_comments_p.text\n",
    "\n",
    "        questions.append(question)\n",
    "\n",
    "    # Save to JSON\n",
    "    output = {\n",
    "        \"quiz_title\": quiz_title,\n",
    "        \"questions\": questions\n",
    "    }\n",
    "    save_canvas_images_development()\n",
    "    return output\n",
    "\n",
    "\n",
    "def moved_processed_file(file):\n",
    "    shutil.move(rf\"{os.path.join(to_process_directory, file)}\", rf\"{os.path.join(processed_directory, file)}\")\n",
    "\n",
    "def get_processed_quizes(db_path=default_raw_db_path, debug=0):\n",
    "    if not os.path.exists(db_path):\n",
    "        with open(db_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump({\"quizzes\": []}, f)\n",
    "\n",
    "    with open(db_path, 'r', encoding='utf-8') as f:\n",
    "        db = json.load(f)\n",
    "    quizzes = [quiz[\"quiz_title\"] for quiz in db.get(\"quizzes\", [])]\n",
    "    if debug:\n",
    "        print(f\"Processed quizzes: {quizzes}\")\n",
    "    return quizzes\n",
    "\n",
    "def insert_json_quiz_into_db(quiz_data, db_path=default_raw_db_path):\n",
    "    if not os.path.exists(db_path):\n",
    "        with open(db_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump({\"quizzes\": []}, f)\n",
    "\n",
    "    # Read current database\n",
    "    with open(db_path, 'r', encoding='utf-8') as f:\n",
    "        db = json.load(f)\n",
    "\n",
    "    # Check for existing titles and increment suffix if needed\n",
    "    base_title = quiz_data[\"quiz_title\"]\n",
    "    existing_titles = [quiz[\"quiz_title\"] for quiz in db.get(\"quizzes\", [])]\n",
    "    new_title = base_title\n",
    "    suffix = 2\n",
    "    while new_title in existing_titles:\n",
    "        new_title = f\"{base_title}_{suffix}\"\n",
    "        suffix += 1\n",
    "    quiz_data[\"quiz_title\"] = new_title\n",
    "\n",
    "    # Add new quiz to database\n",
    "    db[\"quizzes\"].append(quiz_data)\n",
    "\n",
    "    # Write updated database\n",
    "    with open(db_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(db, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    # print(f\"Added quiz '{new_title}' to database.\")\n",
    "    return True\n",
    "\n",
    "# Now update your file processing function to use this\n",
    "def process_file(file_name):\n",
    "    file_path = os.path.join(to_process_directory, file_name)\n",
    "    quiz_data = extract_quiz_to_json(file_path)\n",
    "    \n",
    "    if insert_json_quiz_into_db(quiz_data):\n",
    "        os.makedirs(processed_directory, exist_ok=True)\n",
    "        \n",
    "        shutil.move(file_path, os.path.join(processed_directory, file_name))\n",
    "    else:\n",
    "        print(f\"Skipped {file_name}, quiz already in database.\")\n",
    "\n",
    "def process_directory(folder_path=to_process_directory):\n",
    "    for file in os.listdir(folder_path):\n",
    "        if file.endswith(\".html\"):\n",
    "            process_file(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "692d92ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_directory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "45492715",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indexed_quiz_titles(quiz_title, db_path=default_processed_by_quiz_db_path):\n",
    "    # print(\"\\n\", quiz_title, end=\"\")\n",
    "    try:\n",
    "        with open(db_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            refined_db = json.load(f)\n",
    "\n",
    "        for idx, quiz in enumerate(refined_db):\n",
    "            if quiz[\"quiz_title\"] == quiz_title:\n",
    "                # print(f\" == {quiz['quiz_title']}\")\n",
    "                return idx\n",
    "            # else:\n",
    "            #     print(f\" != {quiz['quiz_title']}\", end=\"\")\n",
    "        return -1\n",
    "    except FileNotFoundError:\n",
    "        return -1\n",
    "\n",
    "# def refine_quiz_db_by_quiz(raw_db):\n",
    "#     # Track unique questions and assign IDs\n",
    "#     question_bank = {}\n",
    "#     question_id_counter = 1\n",
    "#     refined_quizzes = []\n",
    "\n",
    "#     pattern = r'_\\d+$'\n",
    "    \n",
    "#     process_last = []\n",
    "#     for quiz in raw_db[\"quizzes\"]:\n",
    "#         if quiz[\"quiz_title\"].startswith(\"Quiz\") or quiz[\"quiz_title\"].startswith(\"SQ midterm\"):\n",
    "#             process_last.append(quiz[\"quiz_title\"])\n",
    "\n",
    "#     sorted_quizzes = sorted(raw_db[\"quizzes\"], key=lambda quiz: (\n",
    "#         quiz[\"quiz_title\"] in process_last,  # False (0) comes before True (1)\n",
    "#         quiz[\"quiz_title\"]  # Secondary sort by title for consistent ordering\n",
    "#     ))\n",
    "\n",
    "#     print(sorted_quizzes)\n",
    "\n",
    "#     for quiz in sorted_quizzes:\n",
    "#         base_quiz_title = re.sub(pattern, '', quiz[\"quiz_title\"])\n",
    "\n",
    "#         refined_quiz = {\n",
    "#             \"quiz_title\": base_quiz_title,\n",
    "#             \"questions\": []\n",
    "#         }\n",
    "#         unique_count = 0\n",
    "\n",
    "#         for q in quiz[\"questions\"]:\n",
    "#             q_text = q[\"question\"].strip()\n",
    "#             q_image_url = q.get(\"question_image_url\", \"\")\n",
    "#             unique_key = (q_text, q_image_url)\n",
    "\n",
    "#             # Check if question is unique\n",
    "#             if unique_key not in question_bank:\n",
    "#                 question_bank[unique_key] = question_id_counter\n",
    "#                 unique = True\n",
    "#                 q_id = question_id_counter\n",
    "#                 question_id_counter += 1\n",
    "#                 unique_count += 1\n",
    "#             else:\n",
    "#                 continue\n",
    "\n",
    "#             # Build options list\n",
    "#             options = []\n",
    "#             for ans in q[\"answers\"]:\n",
    "#                 options.append({\n",
    "#                     \"text\": ans[\"text\"],\n",
    "#                     \"is_correct\": ans[\"is_correct\"],\n",
    "#                     \"comment\": ans.get(\"comment\")\n",
    "#                 })\n",
    "\n",
    "#             refined_quiz[\"questions\"].append({\n",
    "#                 \"question\": q_text,\n",
    "#                 \"question_image_url\": q_image_url,\n",
    "#                 \"unique\": unique,\n",
    "#                 \"id\": q_id,\n",
    "#                 \"options\": options,\n",
    "#                 \"neutral_comments\": q.get(\"neutral_comments\")\n",
    "#             })\n",
    "\n",
    "#         # Check if this base title already exists in our refined_quizzes list\n",
    "#         existing_quiz_index = -1\n",
    "#         for idx, existing_quiz in enumerate(refined_quizzes):\n",
    "#             if existing_quiz[\"quiz_title\"] == base_quiz_title:\n",
    "#                 existing_quiz_index = idx\n",
    "#                 break\n",
    "        \n",
    "#         if existing_quiz_index == -1:\n",
    "#             # This is the first time we see this base quiz title\n",
    "#             refined_quiz[\"unique_questions\"] = unique_count\n",
    "#             refined_quizzes.append(refined_quiz)\n",
    "#         else:\n",
    "#             # This quiz already exists, merge questions\n",
    "#             # print(f\"Merging questions from '{quiz['quiz_title']}' into '{base_quiz_title}'\")\n",
    "#             refined_quizzes[existing_quiz_index][\"questions\"].extend(refined_quiz[\"questions\"])\n",
    "#             refined_quizzes[existing_quiz_index][\"unique_questions\"] += unique_count\n",
    "    \n",
    "#     return refined_quizzes\n",
    "\n",
    "# Usage:\n",
    "with open(default_raw_db_path, encoding=\"utf-8\") as f:\n",
    "    raw_db = json.load(f)\n",
    "\n",
    "# refined_db = refine_quiz_db_by_quiz(raw_db)\n",
    "\n",
    "# with open(default_processed_by_quiz_db_path, \"w\", encoding=\"utf-8\") as f:\n",
    "#     json.dump(refined_db, f, indent=2, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "9f887503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base processing quiz: SQ topic 3 level 1c (Chapter 4) --> SQ topic 3\n"
     ]
    }
   ],
   "source": [
    "def refine_quiz_db_by_topic(raw_db):\n",
    "    # Track unique questions and assign IDs\n",
    "    question_bank = {}\n",
    "    question_id_counter = 1\n",
    "    refined_quizzes = []\n",
    "\n",
    "    base_quiz_title_pattern = r'((SQ topics?\\s\\d+(-\\d+)?(\\s(and)\\s\\d+)?)|(Quiz \\d+)|(SQ midterm \\d+))'\n",
    "\n",
    "    process_second_pattern = r\"SQ topics?\\s\\d+-\\d+\"\n",
    "    \n",
    "    process_third = []\n",
    "    process_second = []\n",
    "    for quiz in raw_db[\"quizzes\"]:\n",
    "        if quiz[\"quiz_title\"].startswith(\"Quiz\") or quiz[\"quiz_title\"].startswith(\"SQ midterm\"):\n",
    "            process_third.append(quiz[\"quiz_title\"])\n",
    "        elif re.match(process_second_pattern, quiz[\"quiz_title\"]):\n",
    "            # print(f\"Processing second pattern quiz: {re.match(process_second_pattern, quiz['quiz_title']).group(0)}\")\n",
    "            title2 = re.match(process_second_pattern, quiz['quiz_title']).group(0)\n",
    "            # print(f\"Processing second pattern quiz: {title2}\")\n",
    "            process_second.append(quiz[\"quiz_title\"])\n",
    "\n",
    "    sorted_quizzes = sorted(raw_db[\"quizzes\"], key=lambda quiz: (\n",
    "        3 if quiz[\"quiz_title\"] in process_third else 2 if quiz[\"quiz_title\"] in process_second else 1,\n",
    "        # quiz[\"quiz_title\"]  # Secondary sort by title for consistent ordering\n",
    "    ))\n",
    "\n",
    "    # print(sorted_quizzes)\n",
    "\n",
    "    for quiz in sorted_quizzes:\n",
    "        topic_title = re.match(base_quiz_title_pattern, quiz['quiz_title'])\n",
    "        if topic_title:\n",
    "            topic_title = topic_title.group(1)\n",
    "\n",
    "        if quiz['quiz_title'] == \"\" and len(quiz['questions']) == 0:\n",
    "            continue\n",
    "        print(f\"base processing quiz: {quiz['quiz_title']} --> {topic_title if topic_title else quiz['quiz_title']}\")\n",
    "\n",
    "        if not topic_title:\n",
    "            topic_title = quiz['quiz_title']\n",
    "\n",
    "        base_quiz_title = topic_title\n",
    "\n",
    "        # print(f\"quiz title: '{quiz['quiz_title']}' -> base title: '{base_quiz_title}'\")\n",
    "\n",
    "        refined_quiz = {\n",
    "            \"quiz_title\": base_quiz_title,\n",
    "            \"questions\": []\n",
    "        }\n",
    "        unique_count = 0\n",
    "\n",
    "        for q in quiz[\"questions\"]:\n",
    "            q_text = q[\"question\"].strip()\n",
    "            q_image_url = q.get(\"question_image_url\", \"\")\n",
    "            q_options = frozenset([(options[\"text\"], options[\"is_correct\"]) for options in q.get(\"answers\", [])])\n",
    "            unique_key = (q_text, str(q_image_url), q_options)\n",
    "\n",
    "            # Check if question is unique\n",
    "            if unique_key not in question_bank:\n",
    "                question_bank[unique_key] = question_id_counter\n",
    "                unique = True\n",
    "                q_id = question_id_counter\n",
    "                question_id_counter += 1\n",
    "                unique_count += 1\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            # Build options list\n",
    "            options = []\n",
    "            for ans in q[\"answers\"]:\n",
    "                options.append({\n",
    "                    \"text\": ans[\"text\"],\n",
    "                    \"is_correct\": ans[\"is_correct\"],\n",
    "                    # \"comment\": ans.get(\"comment\")\n",
    "                })\n",
    "\n",
    "            refined_quiz[\"questions\"].append({\n",
    "                \"raw_html_question\": q.get(\"raw_html_question\"),\n",
    "                \"question\": q_text,\n",
    "                \"question_image_url\": q_image_url,\n",
    "                \"unique\": unique,\n",
    "                \"id\": q_id,\n",
    "                \"options\": options,\n",
    "                \"comments\": q.get(\"comments\"),\n",
    "                \"raw_html_comments\": q.get(\"raw_html_comments\"),\n",
    "                \"comments_image_url\": q.get(\"comments_image_url\", [])\n",
    "            })\n",
    "\n",
    "        # Check if this base title already exists in our refined_quizzes list\n",
    "        existing_quiz_index = -1\n",
    "        for idx, existing_quiz in enumerate(refined_quizzes):\n",
    "            if existing_quiz[\"quiz_title\"] == base_quiz_title:\n",
    "                existing_quiz_index = idx\n",
    "                break\n",
    "        \n",
    "        if existing_quiz_index == -1:\n",
    "            # This is the first time we see this base quiz title\n",
    "            refined_quiz[\"unique_questions\"] = unique_count\n",
    "            refined_quizzes.append(refined_quiz)\n",
    "        else:\n",
    "            # This quiz already exists, merge questions\n",
    "            # print(f\"Merging questions from '{quiz['quiz_title']}' into '{base_quiz_title}'\")\n",
    "            refined_quizzes[existing_quiz_index][\"questions\"].extend(refined_quiz[\"questions\"])\n",
    "            refined_quizzes[existing_quiz_index][\"unique_questions\"] += unique_count\n",
    "    \n",
    "    return refined_quizzes\n",
    "\n",
    "# Usage:\n",
    "with open(default_raw_db_path, encoding=\"utf-8\") as f:\n",
    "    raw_db = json.load(f)\n",
    "\n",
    "refined_db = refine_quiz_db_by_topic(raw_db)\n",
    "\n",
    "with open(default_processed_by_topics_db_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(refined_db, f, indent=2, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "5214bbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_quiz_titles_and_unique_questions_table(db_path=default_processed_by_quiz_db_path):\n",
    "    with open(db_path, encoding=\"utf-8\") as f:\n",
    "        quizzes = json.load(f)\n",
    "    col_1_len = 60\n",
    "    col_2_len = 15\n",
    "    print(f\"{'Quiz Title':<{col_1_len}} | {'Unique Questions':<{col_2_len}}\")\n",
    "    print(\"-\" * (col_1_len + col_2_len))\n",
    "    unique_count = 0\n",
    "    for quiz in quizzes:\n",
    "        title = quiz.get('quiz_title', '(no title)')\n",
    "        # if \"SQ topic 2 level\" not in title:\n",
    "        #     continue\n",
    "        unique_q = quiz.get('unique_questions', 0)\n",
    "        unique_count += unique_q\n",
    "        print(f\"{title:<{col_1_len}} | {unique_q:<{col_2_len}}\")\n",
    "    print(f\"{'Total':<{col_1_len}} | {unique_count:<{col_2_len}}\")\n",
    "\n",
    "# print_quiz_titles_and_unique_questions_table(db_path=default_processed_by_quiz_db_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "74ff9fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quiz Title                                                   | Unique Questions\n",
      "---------------------------------------------------------------------------\n",
      "SQ topic 3                                                   | 10             \n",
      "Total                                                        | 10             \n"
     ]
    }
   ],
   "source": [
    "print_quiz_titles_and_unique_questions_table(db_path=default_processed_by_topics_db_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "4cda04ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_canvas_images(canvas_images_fp=canvas_images_development_fp, img_dir=img_dir_from_data_compilation):\n",
    "    with open(canvas_images_fp, \"r\", encoding=\"utf-8\") as f:\n",
    "        canvas_images = json.load(f)\n",
    "        # canvas_images = canvas_images[:10] # Limit to first 1 for testing\n",
    "\n",
    "        for idx, img in enumerate(canvas_images):\n",
    "            img_verifier = img.split(\"verifier=\")[-1].strip()\n",
    "            filename = f\"{img_verifier}.jpg\"\n",
    "            filepath = os.path.join(img_dir, filename)\n",
    "\n",
    "            if os.path.exists(filepath):\n",
    "                # print(f\"Image already exists, skipping: {filename}\")\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                response = requests.get(img)\n",
    "                if response.status_code == 200:\n",
    "                    with open(filepath, 'wb') as f:\n",
    "                        f.write(response.content)\n",
    "                    print(f\"Downloaded: {filename}\")\n",
    "                else:\n",
    "                    print(f\"Failed to download image {img_verifier}.jpg: Status {response.status_code}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error downloading image {img_verifier}.jpg: {e}\")\n",
    "\n",
    "download_canvas_images()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
